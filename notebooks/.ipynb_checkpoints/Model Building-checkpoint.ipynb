{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50b5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a990c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"]=\"C:\\Spark\\spark-3.3.2-bin-hadoop2\\python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-18.0.2.1\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\Spark\\spark-3.3.2-bin-hadoop2\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.9.5-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604174d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-0OH3S55:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>r_eda</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2cce257e9a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"r_model\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15835cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- subject_id: string (nullable = true)\n",
      " |-- hadm_id: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- db_wbc: string (nullable = true)\n",
      " |-- basophils_abs: string (nullable = true)\n",
      " |-- eosinophils_abs: string (nullable = true)\n",
      " |-- lymphocytes_abs: string (nullable = true)\n",
      " |-- monocytes_abs: string (nullable = true)\n",
      " |-- neutrophils_abs: string (nullable = true)\n",
      " |-- basophils: string (nullable = true)\n",
      " |-- eosinophils: string (nullable = true)\n",
      " |-- lymphocytes: string (nullable = true)\n",
      " |-- monocytes: string (nullable = true)\n",
      " |-- neutrophils: string (nullable = true)\n",
      " |-- aniongap: string (nullable = true)\n",
      " |-- bicarbonate: string (nullable = true)\n",
      " |-- bun: string (nullable = true)\n",
      " |-- calcium: string (nullable = true)\n",
      " |-- chloride: string (nullable = true)\n",
      " |-- creatinine: string (nullable = true)\n",
      " |-- glucose: string (nullable = true)\n",
      " |-- sodium: string (nullable = true)\n",
      " |-- potassium: string (nullable = true)\n",
      " |-- inr: string (nullable = true)\n",
      " |-- pt: string (nullable = true)\n",
      " |-- ptt: string (nullable = true)\n",
      " |-- hematocrit: string (nullable = true)\n",
      " |-- hemoglobin: string (nullable = true)\n",
      " |-- mch: string (nullable = true)\n",
      " |-- mchc: string (nullable = true)\n",
      " |-- mcv: string (nullable = true)\n",
      " |-- platelet: string (nullable = true)\n",
      " |-- rbc: string (nullable = true)\n",
      " |-- rdw: string (nullable = true)\n",
      " |-- wbc: string (nullable = true)\n",
      " |-- scr_min: string (nullable = true)\n",
      " |-- ckd: string (nullable = true)\n",
      " |-- mdrd_est: string (nullable = true)\n",
      " |-- scr_baseline: string (nullable = true)\n",
      " |-- alt: string (nullable = true)\n",
      " |-- alp: string (nullable = true)\n",
      " |-- ast: string (nullable = true)\n",
      " |-- bilirubin_total: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- subject_id: string (nullable = true)\n",
      " |-- hadm_id: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- db_wbc: string (nullable = true)\n",
      " |-- basophils_abs: string (nullable = true)\n",
      " |-- eosinophils_abs: string (nullable = true)\n",
      " |-- lymphocytes_abs: string (nullable = true)\n",
      " |-- monocytes_abs: string (nullable = true)\n",
      " |-- neutrophils_abs: string (nullable = true)\n",
      " |-- basophils: string (nullable = true)\n",
      " |-- eosinophils: string (nullable = true)\n",
      " |-- lymphocytes: string (nullable = true)\n",
      " |-- monocytes: string (nullable = true)\n",
      " |-- neutrophils: string (nullable = true)\n",
      " |-- aniongap: string (nullable = true)\n",
      " |-- bicarbonate: string (nullable = true)\n",
      " |-- bun: string (nullable = true)\n",
      " |-- calcium: string (nullable = true)\n",
      " |-- chloride: string (nullable = true)\n",
      " |-- creatinine: string (nullable = true)\n",
      " |-- glucose: string (nullable = true)\n",
      " |-- sodium: string (nullable = true)\n",
      " |-- potassium: string (nullable = true)\n",
      " |-- inr: string (nullable = true)\n",
      " |-- pt: string (nullable = true)\n",
      " |-- ptt: string (nullable = true)\n",
      " |-- hematocrit: string (nullable = true)\n",
      " |-- hemoglobin: string (nullable = true)\n",
      " |-- mch: string (nullable = true)\n",
      " |-- mchc: string (nullable = true)\n",
      " |-- mcv: string (nullable = true)\n",
      " |-- platelet: string (nullable = true)\n",
      " |-- rbc: string (nullable = true)\n",
      " |-- rdw: string (nullable = true)\n",
      " |-- wbc: string (nullable = true)\n",
      " |-- scr_min: string (nullable = true)\n",
      " |-- ckd: string (nullable = true)\n",
      " |-- mdrd_est: string (nullable = true)\n",
      " |-- scr_baseline: string (nullable = true)\n",
      " |-- alt: string (nullable = true)\n",
      " |-- alp: string (nullable = true)\n",
      " |-- ast: string (nullable = true)\n",
      " |-- bilirubin_total: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_data = spark.read.option(\"header\",\"true\").csv(\"../data/EDA/clustering_data.csv\")\n",
    "cluster_data.printSchema()\n",
    "cluster_data = cluster_data.drop(\"_c0\")\n",
    "cluster_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabba477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- subject_id: string (nullable = true)\n",
      " |-- charlson_comorbidity_index: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- subject_id: string (nullable = true)\n",
      " |-- charlson_comorbidity_index: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_data = spark.read.option(\"header\",\"true\").csv(\"../data/EDA/prediction_value.csv\")\n",
    "predict_data.printSchema()\n",
    "predict_data = predict_data.drop(\"_c0\")\n",
    "predict_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5462a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove subject_id and hadm_id columns\n",
    "cluster_data = cluster_data.drop(\"subject_id\",\"hadm_id\")\n",
    "predict_data = predict_data.drop(\"subject_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b3c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(cluster_data.count())\n",
    "print(predict_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a735bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- db_wbc: string (nullable = true)\n",
      " |-- basophils_abs: string (nullable = true)\n",
      " |-- eosinophils_abs: string (nullable = true)\n",
      " |-- lymphocytes_abs: string (nullable = true)\n",
      " |-- monocytes_abs: string (nullable = true)\n",
      " |-- neutrophils_abs: string (nullable = true)\n",
      " |-- basophils: string (nullable = true)\n",
      " |-- eosinophils: string (nullable = true)\n",
      " |-- lymphocytes: string (nullable = true)\n",
      " |-- monocytes: string (nullable = true)\n",
      " |-- neutrophils: string (nullable = true)\n",
      " |-- aniongap: string (nullable = true)\n",
      " |-- bicarbonate: string (nullable = true)\n",
      " |-- bun: string (nullable = true)\n",
      " |-- calcium: string (nullable = true)\n",
      " |-- chloride: string (nullable = true)\n",
      " |-- creatinine: string (nullable = true)\n",
      " |-- glucose: string (nullable = true)\n",
      " |-- sodium: string (nullable = true)\n",
      " |-- potassium: string (nullable = true)\n",
      " |-- inr: string (nullable = true)\n",
      " |-- pt: string (nullable = true)\n",
      " |-- ptt: string (nullable = true)\n",
      " |-- hematocrit: string (nullable = true)\n",
      " |-- hemoglobin: string (nullable = true)\n",
      " |-- mch: string (nullable = true)\n",
      " |-- mchc: string (nullable = true)\n",
      " |-- mcv: string (nullable = true)\n",
      " |-- platelet: string (nullable = true)\n",
      " |-- rbc: string (nullable = true)\n",
      " |-- rdw: string (nullable = true)\n",
      " |-- wbc: string (nullable = true)\n",
      " |-- scr_min: string (nullable = true)\n",
      " |-- ckd: string (nullable = true)\n",
      " |-- mdrd_est: string (nullable = true)\n",
      " |-- scr_baseline: string (nullable = true)\n",
      " |-- alt: string (nullable = true)\n",
      " |-- alp: string (nullable = true)\n",
      " |-- ast: string (nullable = true)\n",
      " |-- bilirubin_total: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- db_wbc: double (nullable = true)\n",
      " |-- basophils_abs: double (nullable = true)\n",
      " |-- eosinophils_abs: double (nullable = true)\n",
      " |-- lymphocytes_abs: double (nullable = true)\n",
      " |-- monocytes_abs: double (nullable = true)\n",
      " |-- neutrophils_abs: double (nullable = true)\n",
      " |-- basophils: double (nullable = true)\n",
      " |-- eosinophils: double (nullable = true)\n",
      " |-- lymphocytes: double (nullable = true)\n",
      " |-- monocytes: double (nullable = true)\n",
      " |-- neutrophils: double (nullable = true)\n",
      " |-- aniongap: double (nullable = true)\n",
      " |-- bicarbonate: double (nullable = true)\n",
      " |-- bun: double (nullable = true)\n",
      " |-- calcium: double (nullable = true)\n",
      " |-- chloride: double (nullable = true)\n",
      " |-- creatinine: double (nullable = true)\n",
      " |-- glucose: double (nullable = true)\n",
      " |-- sodium: double (nullable = true)\n",
      " |-- potassium: double (nullable = true)\n",
      " |-- inr: double (nullable = true)\n",
      " |-- pt: double (nullable = true)\n",
      " |-- ptt: double (nullable = true)\n",
      " |-- hematocrit: double (nullable = true)\n",
      " |-- hemoglobin: double (nullable = true)\n",
      " |-- mch: double (nullable = true)\n",
      " |-- mchc: double (nullable = true)\n",
      " |-- mcv: double (nullable = true)\n",
      " |-- platelet: double (nullable = true)\n",
      " |-- rbc: double (nullable = true)\n",
      " |-- rdw: double (nullable = true)\n",
      " |-- wbc: double (nullable = true)\n",
      " |-- scr_min: double (nullable = true)\n",
      " |-- ckd: double (nullable = true)\n",
      " |-- mdrd_est: double (nullable = true)\n",
      " |-- scr_baseline: double (nullable = true)\n",
      " |-- alt: double (nullable = true)\n",
      " |-- alp: double (nullable = true)\n",
      " |-- ast: double (nullable = true)\n",
      " |-- bilirubin_total: double (nullable = true)\n",
      " |-- gender: double (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# convert all values to double\n",
    "import pyspark.sql.functions as F\n",
    "print(cluster_data.printSchema())\n",
    "cluster_data = cluster_data.select(*(F.round(F.col(c).cast(\"double\"), 2).alias(c) for c in cluster_data.columns))\n",
    "print(cluster_data.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values with the standard normal values in medical terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18a75201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>db_wbc</th>\n",
       "      <th>basophils_abs</th>\n",
       "      <th>eosinophils_abs</th>\n",
       "      <th>lymphocytes_abs</th>\n",
       "      <th>monocytes_abs</th>\n",
       "      <th>neutrophils_abs</th>\n",
       "      <th>basophils</th>\n",
       "      <th>eosinophils</th>\n",
       "      <th>lymphocytes</th>\n",
       "      <th>...</th>\n",
       "      <th>scr_min</th>\n",
       "      <th>ckd</th>\n",
       "      <th>mdrd_est</th>\n",
       "      <th>scr_baseline</th>\n",
       "      <th>alt</th>\n",
       "      <th>alp</th>\n",
       "      <th>ast</th>\n",
       "      <th>bilirubin_total</th>\n",
       "      <th>gender</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.35</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[52.35, 4.2, nan, nan, nan, nan, nan, nan, nan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.88</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5.17</td>\n",
       "      <td>1.18</td>\n",
       "      <td>12.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>27.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[55.88, 19.0, 0.13, 0.29, 5.17, 1.18, 12.24, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.28</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>18.99</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[46.28, 20.1, 0.22, 0.42, 5.73, 0.94, 18.99, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.53</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.90</td>\n",
       "      <td>6.01</td>\n",
       "      <td>1.17</td>\n",
       "      <td>28.49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[80.53, 6.0, 0.17, 1.9, 6.01, 1.17, 28.49, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.39</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>33.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[81.39, 36.8, 0.0, 0.22, 1.79, 2.21, 33.49, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45.39</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[45.39, 11.5, 0.03, 0.26, 1.56, 1.17, 7.6, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>46.83</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6.32</td>\n",
       "      <td>1.64</td>\n",
       "      <td>14.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.8</td>\n",
       "      <td>70.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[46.83, 7.0, 0.21, 0.39, 6.32, 1.64, 14.35, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>57.99</td>\n",
       "      <td>15.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[57.99, 15.3, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>67.68</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>27.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[67.68, 8.5, 0.02, 0.16, 1.33, 0.5, 2.75, 0.4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>64.21</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[64.21, 8.9, 0.01, 0.11, 1.08, 0.92, 9.08, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  db_wbc  basophils_abs  eosinophils_abs  lymphocytes_abs  \\\n",
       "0   52.35     4.2            NaN              NaN              NaN   \n",
       "1   55.88    19.0           0.13             0.29             5.17   \n",
       "2   46.28    20.1           0.22             0.42             5.73   \n",
       "3   80.53     6.0           0.17             1.90             6.01   \n",
       "4   81.39    36.8           0.00             0.22             1.79   \n",
       "..    ...     ...            ...              ...              ...   \n",
       "95  45.39    11.5           0.03             0.26             1.56   \n",
       "96  46.83     7.0           0.21             0.39             6.32   \n",
       "97  57.99    15.3            NaN              NaN              NaN   \n",
       "98  67.68     8.5           0.02             0.16             1.33   \n",
       "99  64.21     8.9           0.01             0.11             1.08   \n",
       "\n",
       "    monocytes_abs  neutrophils_abs  basophils  eosinophils  lymphocytes  ...  \\\n",
       "0             NaN              NaN        NaN          NaN          NaN  ...   \n",
       "1            1.18            12.24        0.7          1.5         27.2  ...   \n",
       "2            0.94            18.99        1.1          2.1         28.5  ...   \n",
       "3            1.17            28.49        0.5          5.7         18.0  ...   \n",
       "4            2.21            33.49        0.0          2.0         16.0  ...   \n",
       "..            ...              ...        ...          ...          ...  ...   \n",
       "95           1.17             7.60        0.3          3.0         17.4  ...   \n",
       "96           1.64            14.35        1.0          3.0         49.0  ...   \n",
       "97            NaN              NaN        NaN          NaN          NaN  ...   \n",
       "98           0.50             2.75        0.4          3.4         27.9  ...   \n",
       "99           0.92             9.08        0.1          1.0          9.5  ...   \n",
       "\n",
       "    scr_min  ckd  mdrd_est  scr_baseline     alt    alp     ast  \\\n",
       "0       0.3  0.0      0.85           0.3    88.0  103.0    98.0   \n",
       "1       0.4  0.0      0.84           0.4    12.0   56.0    17.0   \n",
       "2       0.8  0.0      0.86           0.8     NaN    NaN     NaN   \n",
       "3       0.8  0.0      0.78           0.8    66.0  163.0   102.0   \n",
       "4       1.1  0.0      1.01           1.1    44.0   99.0   210.0   \n",
       "..      ...  ...       ...           ...     ...    ...     ...   \n",
       "95      0.6  0.0      1.12           0.6    54.0  127.0    36.0   \n",
       "96      0.8  0.0      0.86           0.8    70.0  325.0   139.0   \n",
       "97      0.4  0.0      0.83           0.4  1343.0  125.0  1015.0   \n",
       "98      0.9  0.0      0.81           0.9    16.0   73.0    15.0   \n",
       "99      1.5  1.0      0.82           1.5     7.0  199.0    16.0   \n",
       "\n",
       "    bilirubin_total  gender                                           features  \n",
       "0               1.3     NaN  [52.35, 4.2, nan, nan, nan, nan, nan, nan, nan...  \n",
       "1               0.4     NaN  [55.88, 19.0, 0.13, 0.29, 5.17, 1.18, 12.24, 0...  \n",
       "2               NaN     NaN  [46.28, 20.1, 0.22, 0.42, 5.73, 0.94, 18.99, 1...  \n",
       "3               0.2     NaN  [80.53, 6.0, 0.17, 1.9, 6.01, 1.17, 28.49, 0.5...  \n",
       "4               0.6     NaN  [81.39, 36.8, 0.0, 0.22, 1.79, 2.21, 33.49, 0....  \n",
       "..              ...     ...                                                ...  \n",
       "95              1.5     NaN  [45.39, 11.5, 0.03, 0.26, 1.56, 1.17, 7.6, 0.3...  \n",
       "96              4.6     NaN  [46.83, 7.0, 0.21, 0.39, 6.32, 1.64, 14.35, 1....  \n",
       "97              2.0     NaN  [57.99, 15.3, nan, nan, nan, nan, nan, nan, na...  \n",
       "98              0.2     NaN  [67.68, 8.5, 0.02, 0.16, 1.33, 0.5, 2.75, 0.4,...  \n",
       "99              0.7     NaN  [64.21, 8.9, 0.01, 0.11, 1.08, 0.92, 9.08, 0.1...  \n",
       "\n",
       "[100 rows x 43 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assemble = VectorAssembler(inputCols=cluster_data.columns, outputCol='features')\n",
    "assembled_data = assemble.setHandleInvalid(\"keep\").transform(cluster_data)\n",
    "assembled_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba72bfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>db_wbc</th>\n",
       "      <th>basophils_abs</th>\n",
       "      <th>eosinophils_abs</th>\n",
       "      <th>lymphocytes_abs</th>\n",
       "      <th>monocytes_abs</th>\n",
       "      <th>neutrophils_abs</th>\n",
       "      <th>basophils</th>\n",
       "      <th>eosinophils</th>\n",
       "      <th>lymphocytes</th>\n",
       "      <th>...</th>\n",
       "      <th>ckd</th>\n",
       "      <th>mdrd_est</th>\n",
       "      <th>scr_baseline</th>\n",
       "      <th>alt</th>\n",
       "      <th>alp</th>\n",
       "      <th>ast</th>\n",
       "      <th>bilirubin_total</th>\n",
       "      <th>gender</th>\n",
       "      <th>features</th>\n",
       "      <th>standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.35</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[52.35, 4.2, nan, nan, nan, nan, nan, nan, nan...</td>\n",
       "      <td>[3.2528477642368783, 0.486745135530605, nan, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.88</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5.17</td>\n",
       "      <td>1.18</td>\n",
       "      <td>12.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>27.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[55.88, 19.0, 0.13, 0.29, 5.17, 1.18, 12.24, 0...</td>\n",
       "      <td>[3.472189743372622, 2.201942279781308, nan, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.28</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>18.99</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[46.28, 20.1, 0.22, 0.42, 5.73, 0.94, 18.99, 1...</td>\n",
       "      <td>[2.8756789785841974, 2.3294231486107524, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.53</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.90</td>\n",
       "      <td>6.01</td>\n",
       "      <td>1.17</td>\n",
       "      <td>28.49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[80.53, 6.0, 0.17, 1.9, 6.01, 1.17, 28.49, 0.5...</td>\n",
       "      <td>[5.003855405042899, 0.6953501936151499, nan, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.39</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.21</td>\n",
       "      <td>33.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[81.39, 36.8, 0.0, 0.22, 1.79, 2.21, 33.49, 0....</td>\n",
       "      <td>[5.057292827721863, 4.264814520839586, nan, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45.39</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[45.39, 11.5, 0.03, 0.26, 1.56, 1.17, 7.6, 0.3...</td>\n",
       "      <td>[2.8203774597652704, 1.3327545377623706, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>46.83</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6.32</td>\n",
       "      <td>1.64</td>\n",
       "      <td>14.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.8</td>\n",
       "      <td>70.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[46.83, 7.0, 0.21, 0.39, 6.32, 1.64, 14.35, 1....</td>\n",
       "      <td>[2.9098540744835337, 0.8112418925510083, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>57.99</td>\n",
       "      <td>15.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[57.99, 15.3, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>[3.603297838550078, 1.7731429937186325, nan, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>67.68</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>27.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[67.68, 8.5, 0.02, 0.16, 1.33, 0.5, 2.75, 0.4,...</td>\n",
       "      <td>[4.205400891758394, 0.9850794409547957, nan, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>64.21</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[64.21, 8.9, 0.01, 0.11, 1.08, 0.92, 9.08, 0.1...</td>\n",
       "      <td>[3.9897871049025775, 1.0314361205291391, nan, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  db_wbc  basophils_abs  eosinophils_abs  lymphocytes_abs  \\\n",
       "0   52.35     4.2            NaN              NaN              NaN   \n",
       "1   55.88    19.0           0.13             0.29             5.17   \n",
       "2   46.28    20.1           0.22             0.42             5.73   \n",
       "3   80.53     6.0           0.17             1.90             6.01   \n",
       "4   81.39    36.8           0.00             0.22             1.79   \n",
       "..    ...     ...            ...              ...              ...   \n",
       "95  45.39    11.5           0.03             0.26             1.56   \n",
       "96  46.83     7.0           0.21             0.39             6.32   \n",
       "97  57.99    15.3            NaN              NaN              NaN   \n",
       "98  67.68     8.5           0.02             0.16             1.33   \n",
       "99  64.21     8.9           0.01             0.11             1.08   \n",
       "\n",
       "    monocytes_abs  neutrophils_abs  basophils  eosinophils  lymphocytes  ...  \\\n",
       "0             NaN              NaN        NaN          NaN          NaN  ...   \n",
       "1            1.18            12.24        0.7          1.5         27.2  ...   \n",
       "2            0.94            18.99        1.1          2.1         28.5  ...   \n",
       "3            1.17            28.49        0.5          5.7         18.0  ...   \n",
       "4            2.21            33.49        0.0          2.0         16.0  ...   \n",
       "..            ...              ...        ...          ...          ...  ...   \n",
       "95           1.17             7.60        0.3          3.0         17.4  ...   \n",
       "96           1.64            14.35        1.0          3.0         49.0  ...   \n",
       "97            NaN              NaN        NaN          NaN          NaN  ...   \n",
       "98           0.50             2.75        0.4          3.4         27.9  ...   \n",
       "99           0.92             9.08        0.1          1.0          9.5  ...   \n",
       "\n",
       "    ckd  mdrd_est  scr_baseline     alt    alp     ast  bilirubin_total  \\\n",
       "0   0.0      0.85           0.3    88.0  103.0    98.0              1.3   \n",
       "1   0.0      0.84           0.4    12.0   56.0    17.0              0.4   \n",
       "2   0.0      0.86           0.8     NaN    NaN     NaN              NaN   \n",
       "3   0.0      0.78           0.8    66.0  163.0   102.0              0.2   \n",
       "4   0.0      1.01           1.1    44.0   99.0   210.0              0.6   \n",
       "..  ...       ...           ...     ...    ...     ...              ...   \n",
       "95  0.0      1.12           0.6    54.0  127.0    36.0              1.5   \n",
       "96  0.0      0.86           0.8    70.0  325.0   139.0              4.6   \n",
       "97  0.0      0.83           0.4  1343.0  125.0  1015.0              2.0   \n",
       "98  0.0      0.81           0.9    16.0   73.0    15.0              0.2   \n",
       "99  1.0      0.82           1.5     7.0  199.0    16.0              0.7   \n",
       "\n",
       "    gender                                           features  \\\n",
       "0      NaN  [52.35, 4.2, nan, nan, nan, nan, nan, nan, nan...   \n",
       "1      NaN  [55.88, 19.0, 0.13, 0.29, 5.17, 1.18, 12.24, 0...   \n",
       "2      NaN  [46.28, 20.1, 0.22, 0.42, 5.73, 0.94, 18.99, 1...   \n",
       "3      NaN  [80.53, 6.0, 0.17, 1.9, 6.01, 1.17, 28.49, 0.5...   \n",
       "4      NaN  [81.39, 36.8, 0.0, 0.22, 1.79, 2.21, 33.49, 0....   \n",
       "..     ...                                                ...   \n",
       "95     NaN  [45.39, 11.5, 0.03, 0.26, 1.56, 1.17, 7.6, 0.3...   \n",
       "96     NaN  [46.83, 7.0, 0.21, 0.39, 6.32, 1.64, 14.35, 1....   \n",
       "97     NaN  [57.99, 15.3, nan, nan, nan, nan, nan, nan, na...   \n",
       "98     NaN  [67.68, 8.5, 0.02, 0.16, 1.33, 0.5, 2.75, 0.4,...   \n",
       "99     NaN  [64.21, 8.9, 0.01, 0.11, 1.08, 0.92, 9.08, 0.1...   \n",
       "\n",
       "                                         standardized  \n",
       "0   [3.2528477642368783, 0.486745135530605, nan, n...  \n",
       "1   [3.472189743372622, 2.201942279781308, nan, na...  \n",
       "2   [2.8756789785841974, 2.3294231486107524, nan, ...  \n",
       "3   [5.003855405042899, 0.6953501936151499, nan, n...  \n",
       "4   [5.057292827721863, 4.264814520839586, nan, na...  \n",
       "..                                                ...  \n",
       "95  [2.8203774597652704, 1.3327545377623706, nan, ...  \n",
       "96  [2.9098540744835337, 0.8112418925510083, nan, ...  \n",
       "97  [3.603297838550078, 1.7731429937186325, nan, n...  \n",
       "98  [4.205400891758394, 0.9850794409547957, nan, n...  \n",
       "99  [3.9897871049025775, 1.0314361205291391, nan, ...  \n",
       "\n",
       "[100 rows x 44 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "scale=StandardScaler(inputCol='features',outputCol='standardized')\n",
    "data_scale=scale.fit(assembled_data)\n",
    "data_scale_output=data_scale.transform(assembled_data)\n",
    "data_scale_output.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d7ee251",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o404.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 27.0 failed 1 times, most recent failure: Lost task 0.0 in stage 27.0 (TID 24) (DESKTOP-0OH3S55 executor driver): java.lang.IllegalArgumentException: requirement failed: Both norms should be greater or equal to 0.0, found norm1=NaN, norm2=NaN\r\n\tat scala.Predef$.require(Predef.scala:281)\r\n\tat org.apache.spark.mllib.util.MLUtils$.fastSquaredDistance(MLUtils.scala:543)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure$.fastSquaredDistance(DistanceMeasure.scala:414)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure.findClosest(DistanceMeasure.scala:309)\r\n\tat org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:132)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6(KMeans.scala:307)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6$adapted(KMeans.scala:306)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$4(KMeans.scala:306)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\r\n\tat org.apache.spark.mllib.clustering.KMeans.runAlgorithmWithWeight(KMeans.scala:315)\r\n\tat org.apache.spark.mllib.clustering.KMeans.runWithWeight(KMeans.scala:231)\r\n\tat org.apache.spark.ml.clustering.KMeans.$anonfun$fit$1(KMeans.scala:354)\r\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\r\n\tat org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:329)\r\n\tat org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:272)\r\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:577)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Both norms should be greater or equal to 0.0, found norm1=NaN, norm2=NaN\r\n\tat scala.Predef$.require(Predef.scala:281)\r\n\tat org.apache.spark.mllib.util.MLUtils$.fastSquaredDistance(MLUtils.scala:543)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure$.fastSquaredDistance(DistanceMeasure.scala:414)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure.findClosest(DistanceMeasure.scala:309)\r\n\tat org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:132)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6(KMeans.scala:307)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6$adapted(KMeans.scala:306)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$4(KMeans.scala:306)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      9\u001b[0m     KMeans_algo\u001b[38;5;241m=\u001b[39mKMeans(featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandardized\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mi)\n\u001b[1;32m---> 11\u001b[0m     KMeans_fit\u001b[38;5;241m=\u001b[39m\u001b[43mKMeans_algo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_scale_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     output\u001b[38;5;241m=\u001b[39mKMeans_fit\u001b[38;5;241m.\u001b[39mtransform(data_scale_output)\n\u001b[0;32m     17\u001b[0m     score\u001b[38;5;241m=\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mevaluate(output)\n",
      "File \u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop2\\python\\lib\\pyspark.zip\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop2\\python\\lib\\pyspark.zip\\pyspark\\ml\\wrapper.py:383\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[1;32m--> 383\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop2\\python\\lib\\pyspark.zip\\pyspark\\ml\\wrapper.py:380\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop2\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop2\\python\\lib\\pyspark.zip\\pyspark\\sql\\utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\Spark\\spark-3.3.2-bin-hadoop2\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o404.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 27.0 failed 1 times, most recent failure: Lost task 0.0 in stage 27.0 (TID 24) (DESKTOP-0OH3S55 executor driver): java.lang.IllegalArgumentException: requirement failed: Both norms should be greater or equal to 0.0, found norm1=NaN, norm2=NaN\r\n\tat scala.Predef$.require(Predef.scala:281)\r\n\tat org.apache.spark.mllib.util.MLUtils$.fastSquaredDistance(MLUtils.scala:543)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure$.fastSquaredDistance(DistanceMeasure.scala:414)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure.findClosest(DistanceMeasure.scala:309)\r\n\tat org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:132)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6(KMeans.scala:307)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6$adapted(KMeans.scala:306)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$4(KMeans.scala:306)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\r\n\tat org.apache.spark.mllib.clustering.KMeans.runAlgorithmWithWeight(KMeans.scala:315)\r\n\tat org.apache.spark.mllib.clustering.KMeans.runWithWeight(KMeans.scala:231)\r\n\tat org.apache.spark.ml.clustering.KMeans.$anonfun$fit$1(KMeans.scala:354)\r\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\r\n\tat org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:329)\r\n\tat org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:272)\r\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:577)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Both norms should be greater or equal to 0.0, found norm1=NaN, norm2=NaN\r\n\tat scala.Predef$.require(Predef.scala:281)\r\n\tat org.apache.spark.mllib.util.MLUtils$.fastSquaredDistance(MLUtils.scala:543)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure$.fastSquaredDistance(DistanceMeasure.scala:414)\r\n\tat org.apache.spark.mllib.clustering.EuclideanDistanceMeasure.findClosest(DistanceMeasure.scala:309)\r\n\tat org.apache.spark.mllib.clustering.DistanceMeasure.findClosest(DistanceMeasure.scala:132)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6(KMeans.scala:307)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$6$adapted(KMeans.scala:306)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.mllib.clustering.KMeans.$anonfun$runAlgorithmWithWeight$4(KMeans.scala:306)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "silhouette_score=[]\n",
    "\n",
    "evaluator = ClusteringEvaluator(predictionCol='prediction', featuresCol='standardized', \\\n",
    "                                metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "for i in range(2,10):\n",
    "    \n",
    "    KMeans_algo=KMeans(featuresCol='standardized', k=i)\n",
    "    \n",
    "    KMeans_fit=KMeans_algo.fit(data_scale_output)\n",
    "    \n",
    "    output=KMeans_fit.transform(data_scale_output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    score=evaluator.evaluate(output)\n",
    "    \n",
    "    silhouette_score.append(score)\n",
    "    \n",
    "    print(\"Silhouette Score:\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31bebde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
