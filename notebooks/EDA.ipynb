{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99438f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b60cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"]=\"C:\\Spark\\spark-3.3.2-bin-hadoop2\\python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-18.0.2.1\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\Spark\\spark-3.3.2-bin-hadoop2\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.9.5-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d5ae74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-0OH3S55:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>r_eda</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x158c621f5b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"r_eda\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca69b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.option(\"header\",\"true\").csv(\"../data/r_hosp_demo_dataset.csv\")\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d195811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b66f6d",
   "metadata": {},
   "source": [
    "- All the rows has subject, gender, age, admission id (hadm_id) and charlson_comorbidity_index.\n",
    "- The min and max age values looks good.\n",
    "\n",
    "To Do\n",
    "- Check for valid gender values and remove invalid genders (those other than 'M' and 'F').\n",
    "- Remove columns with more than 50% missing values\n",
    "- impute missing values by calculating the average of the value between the last & next reading for the same subject.\n",
    "- Remove columns with more than 25% missing values after impuatation.\n",
    "- remove rows which has data in less than 25% of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee43a3d",
   "metadata": {},
   "source": [
    "#### Check for valid gender values and remove invalid genders (those other than 'M' and 'F')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for gender values\n",
    "data.groupby(\"gender\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16786795",
   "metadata": {},
   "source": [
    "Gender column values looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a9dc8",
   "metadata": {},
   "source": [
    "#### Remove columns with more than 50% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data.describe().toPandas()\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce37f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identify and get columns with < 50% missing values\n",
    "dt_t = dt.T\n",
    "dt_t.columns = dt_t.iloc[0]\n",
    "dt_t.drop(dt_t.index[0], inplace=True)\n",
    "#dt_t.drop(dt_t.index[89], inplace=True)\n",
    "dt_t[\"count\"] = dt_t['count'].astype(int)\n",
    "dt_t['missing_percentage'] = 100 - (dt_t[\"count\"] / data.count())*100\n",
    "print(dt_t)\n",
    "dt_t = dt_t[dt_t[\"missing_percentage\"] < 50]\n",
    "print(dt_t)\n",
    "print(dt_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5debb",
   "metadata": {},
   "source": [
    "After removing all the columns with missing value % >= 50, we get remaining 45 feature fields which are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10f19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dt_t.shape)\n",
    "dt_t.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd802e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only the identified column data from the data\n",
    "data = data.select(dt_t.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb585123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# round off age by 2 decimal point\n",
    "print(data.printSchema())\n",
    "data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3ce7e",
   "metadata": {},
   "source": [
    "#### type conversion for the columns data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d15c4",
   "metadata": {},
   "source": [
    "Except for Gender, all other columns contain decimal values. Hence converting every column type to decimal with 2 decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d58243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting all number columns to double of precision 2 except for gender\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "cols = data.columns\n",
    "cols.remove(\"gender\")\n",
    "data2 = data.select(*(F.round(F.col(c).cast(\"double\"), 2).alias(c) for c in cols), \"gender\")\n",
    "print(data2.columns)\n",
    "print(data2.printSchema())\n",
    "data2.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64743aee",
   "metadata": {},
   "source": [
    "#### Impute missing values - Calculating the average of the values between the prev & next admission reading for the same subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for verification\n",
    "data2.filter((data2.subject_id == 10040025)).select(\"subject_id\",\"age\",\"basophils_abs\", \"db_wbc\", \"platelet\", \"ast\").orderBy(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb11832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before impute\n",
    "data2.toPandas().to_csv(\"../data/EDA/before_imputation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use window function to impute missing values.\n",
    "# https://sqlrelease.com/get-the-first-non-null-value-per-group-spark-dataframe\n",
    "from pyspark.sql.window import Window\n",
    "subject_win_prev = Window.partitionBy(\"subject_id\").orderBy(F.desc(\"age\")).rowsBetween(Window.currentRow+1,Window.unboundedFollowing)\n",
    "subject_win_next = Window.partitionBy(\"subject_id\").orderBy(\"age\").rowsBetween(Window.currentRow+1,Window.unboundedFollowing)\n",
    "#wi_next = Window.partitionBy(\"subject_id\").orderBy(F.desc(\"age\"))\n",
    "for c in data2.columns:\n",
    "    if (c not in (\"subject_id\", \"age\", \"gender\", \"hadm_id\", \"charlson_comorbidity_index\")):\n",
    "            data2 = data2.withColumn('temp_' + c + 'prev', F.first(c, ignorenulls = True).over(subject_win_prev)) \\\n",
    "            .withColumn('temp_' + c + 'next', F.first(c, ignorenulls = True).over(subject_win_next)) \\\n",
    "            .withColumn(c , F.when(F.col(c).isNotNull() ,F.col(c)) \\\n",
    "                        .when(F.col(c).isNull() & F.col('temp_' + c + 'prev').isNull(), F.col('temp_' + c + 'next')) \\\n",
    "                        .when(F.col(c).isNull() & F.col('temp_' + c + 'next').isNull(), F.col('temp_' + c + 'prev')) \\\n",
    "                        .otherwise(((F.col('temp_' + c + 'prev') + F.col('temp_' + c + 'next'))/2))) \\\n",
    "            .drop('temp_' + c + 'prev', 'temp_' + c + 'next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8661c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# same sample for verification\n",
    "data2.filter((data2.subject_id == 10040025)).select(\"subject_id\",\"age\",\"basophils_abs\", \"db_wbc\", \"platelet\", \"ast\").orderBy(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35238458",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.toPandas().to_csv(\"../data/EDA/after_imputation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c568c4",
   "metadata": {},
   "source": [
    "#### Remove columns with more than 25% missing values after impuatation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and get columns with < 25% missing values\n",
    "dt = data2.describe().toPandas()\n",
    "print(dt)\n",
    "dt_t = dt.T\n",
    "dt_t.columns = dt_t.iloc[0]\n",
    "dt_t.drop(dt_t.index[0], inplace=True)\n",
    "dt_t[\"count\"] = dt_t['count'].astype(int)\n",
    "dt_t['missing_percentage'] = 100 - (dt_t[\"count\"] / data.count())*100\n",
    "print(dt_t)\n",
    "print(dt_t.shape)\n",
    "dt_t = dt_t[dt_t[\"missing_percentage\"] < 25]\n",
    "print(dt_t)\n",
    "print(dt_t.shape)\n",
    "dt_t.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_t.shape)\n",
    "dt_t.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb229a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only the identified column data from the data\n",
    "print(data2.columns)\n",
    "print(len(data2.columns))\n",
    "data2 = data2.select(dt_t.index.values.tolist())\n",
    "print(data2.columns)\n",
    "print(len(data2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59341cea",
   "metadata": {},
   "source": [
    "No columns removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ae480",
   "metadata": {},
   "source": [
    "#### retain rows which has missing values less than 25% of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e9252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate missing percentage for every row\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "for c in data2.columns:\n",
    "    if ('missing_' not in c) and (c not in (\"subject_id\", \"age\", \"gender\", \"hadm_id\", \"charlson_comorbidity_index\")):\n",
    "            data2 = data2.withColumn('missing_' + c, F.when(F.col(c).isNull(), 1).otherwise(0))\n",
    "\n",
    "data2 = data2.withColumn('missing_percentage', (reduce(add, [F.col(x) for x in data2.columns if \"missing_\" in x])/(len(data2.columns)-5))*100)\n",
    "data2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.groupBy(\"missing_percentage\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.filter(\"missing_percentage < 25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2.count())\n",
    "print(data3.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce779fa",
   "metadata": {},
   "source": [
    "None of the rows has missing % >= 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa21b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data3.columns))\n",
    "condition = lambda x: (\"missing_\" in x)\n",
    "data3 = data3.drop(*filter(condition, data3.columns))\n",
    "len(data3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.toPandas().to_csv(\"../data/EDA/after_eda.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = spark.read.option(\"header\",\"true\").csv(\"../data/EDA/after_eda.csv\")\n",
    "data4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64804d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first admission readings and last admission co-morbidity index value\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "subject_win = Window.partitionBy(\"subject_id\").orderBy((\"age\"))\n",
    "base_data = data4.withColumn(\"row\",F.row_number().over(subject_win)) \\\n",
    "  .filter(F.col(\"row\") == 1).drop(\"row\", \"charlson_comorbidity_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec249d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_win_predict = Window.partitionBy(\"subject_id\").orderBy(F.desc(\"age\"))\n",
    "base_data_predict = data4.withColumn(\"row\",F.row_number().over(subject_win_predict)) \\\n",
    "  .filter(F.col(\"row\") == 1).select(\"subject_id\", \"charlson_comorbidity_index\")\n",
    "base_data_predict.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82306230",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_data.columns)\n",
    "print(base_data_predict.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = base_data.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3b7c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_data_predict.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data.toPandas().to_csv(\"../data/EDA/clustering_data.csv\")\n",
    "base_data_predict.toPandas().to_csv(\"../data/EDA/prediction_value.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5105e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
